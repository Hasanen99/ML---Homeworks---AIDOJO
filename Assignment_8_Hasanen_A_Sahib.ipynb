{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 8: Hasanen A. Sahib",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasanen99/ML-Homeworks-AIDOJO/blob/main/Assignment_8_Hasanen_A_Sahib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment 08: Advanced Sequence Applications\n",
        "\n",
        "This Week's assignment is to train sequence models on the `Cafe Chatbot Data`.\n",
        "\n",
        "Before starting copy this file and work on your own copy by following the below steps: <br>\n",
        "`File > Save Copy in Drive`. Then add your name to the file (e.g., Assignment 07: Sequence Modeling - Zahraa Dhafer).\n",
        "\n",
        "**DATASET**\n",
        "This dataset consists of three csv files, you'll be working on the conversationo CSV file which contains two columns of questions and answers.<br><br>\n",
        "**Submission Deadline: Saturday, 3/12/2022 at 3:00 PM**\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "1. Import all necessary libraries for the sequence modeling project.\n",
        "2. Download the dataset (the link is provided below).\n",
        "3. Read data from CSV file.\n",
        "4. Prepare the data:\n",
        "*   Clean the sentences by removing special characters.\n",
        "*   Add a start and end token to each sentence.\n",
        "*   Tokenize the sentences.\n",
        "*   Pad each sentence to a maximum length.\n",
        "<br>\n",
        "5. Create the Data Pipeline for the Model\n",
        "6. Create the Seq2Seq Model Architecture.<br>\n",
        "**Note**: Use Adam optimizer and the appropriate loss function.\n",
        "7. Create the Optimizer and the Loss Function.\n",
        "8. Create the Training Step.\n",
        "9. Create the Training Loop\n",
        "\n",
        "**Note:** you can overfit your model.<br>\n",
        "**HINTS:**\n",
        "Set the new hyperparameters like vocabulary size, input length (i.e. max sequence length) in a separate cell after the import cell in your notebook (failing to do so will affect your style score)\n",
        "\n",
        "**Note:** To get the best performance from the model, manually tune the hyperparameters of the model. \n",
        "\n",
        "Find relevant links below:<br>\n",
        "\n",
        "[Assignment Colab File](https://colab.research.google.com/drive/1N6IcInQFF0iJdl8pruUvb4-rAacE0IBC?usp=sharing)<br>\n",
        "\n",
        "[Dataset](https://www.kaggle.com/sonalibhoir/cafe-chatbot-dataset?select=conversationo.csv)\n",
        "\n",
        "[Submission Form](https://docs.google.com/forms/d/e/1FAIpQLSf-WkcxjmZcxdUcu5OG7ZxFOsQu-qBy-u1UFNPRkWmjeW7w3g/viewform?usp=pp_url)<br>\n",
        "\n",
        "\n",
        "Good luck and feel free to ask any questions in the or on the Questions channel."
      ],
      "metadata": {
        "id": "AU78WMPocdFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Import all necessary libraries for the sequence modeling project"
      ],
      "metadata": {
        "id": "NY3o4kreqOLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "import re\n",
        "from sklearn import model_selection"
      ],
      "metadata": {
        "id": "0nYUDKQBic7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Download the dataset"
      ],
      "metadata": {
        "id": "dG-8I4sUqatO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d sonalibhoir/cafe-chatbot-dataset"
      ],
      "metadata": {
        "id": "TPmmLNyHaq8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793fee80-bfab-4324-f2d6-5167d44d599e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading cafe-chatbot-dataset.zip to /content\n",
            "  0% 0.00/7.55k [00:00<?, ?B/s]\n",
            "100% 7.55k/7.55k [00:00<00:00, 7.88MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/cafe-chatbot-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuu408JyOzmm",
        "outputId": "4b23f58d-12d4-40e7-bc7c-4189e8860005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/cafe-chatbot-dataset.zip\n",
            "  inflating: Item_to_id.csv          \n",
            "  inflating: conversationo.csv       \n",
            "  inflating: food.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Read data from CSV file"
      ],
      "metadata": {
        "id": "MLA4G5gFqjOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/conversationo.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yce54RnBO6gh",
        "outputId": "6c7bd2df-ba1a-4576-88dd-b7567df6e500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Question  \\\n",
              "0                                         hey   \n",
              "1                            do u have coffee   \n",
              "2    i will take one espresso and 5 americano   \n",
              "3                            anything special   \n",
              "4                           suggest something   \n",
              "..                                        ...   \n",
              "974           what is price of French Coffee    \n",
              "975         what is price of Iced Coffee Late   \n",
              "976          what is price of Latte Macchiato   \n",
              "977     what is price of Wainans Choco Coffee   \n",
              "978                           book me a table   \n",
              "\n",
              "                                                answer  \n",
              "0                           Hello! How may I help you.  \n",
              "1    Yes sir  Simple Coffee ,Cappuchino, Americano,...  \n",
              "2    Sir thanks for your order. You have ordered 1 ...  \n",
              "3    We have coffe,pastries,puff pastries and milks...  \n",
              "4    We have coffe,pastries,puff pastries and milks...  \n",
              "..                                                 ...  \n",
              "974  Its our one of best, you can enjoy it at just ...  \n",
              "975  Its our one of best, you can enjoy it at just ...  \n",
              "976  Its our one of best, you can enjoy it at just ...  \n",
              "977  Its our one of best, you can enjoy it at just ...  \n",
              "978  To book a table you can click on last icon on ...  \n",
              "\n",
              "[979 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28894902-a6c9-4e64-939a-e210fd87cedd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hey</td>\n",
              "      <td>Hello! How may I help you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>do u have coffee</td>\n",
              "      <td>Yes sir  Simple Coffee ,Cappuchino, Americano,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i will take one espresso and 5 americano</td>\n",
              "      <td>Sir thanks for your order. You have ordered 1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anything special</td>\n",
              "      <td>We have coffe,pastries,puff pastries and milks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suggest something</td>\n",
              "      <td>We have coffe,pastries,puff pastries and milks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>what is price of French Coffee</td>\n",
              "      <td>Its our one of best, you can enjoy it at just ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>what is price of Iced Coffee Late</td>\n",
              "      <td>Its our one of best, you can enjoy it at just ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>what is price of Latte Macchiato</td>\n",
              "      <td>Its our one of best, you can enjoy it at just ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>what is price of Wainans Choco Coffee</td>\n",
              "      <td>Its our one of best, you can enjoy it at just ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>book me a table</td>\n",
              "      <td>To book a table you can click on last icon on ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>979 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28894902-a6c9-4e64-939a-e210fd87cedd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28894902-a6c9-4e64-939a-e210fd87cedd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28894902-a6c9-4e64-939a-e210fd87cedd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO4vxWolRP7F",
        "outputId": "e93ca2e2-b277-4bc4-a24a-d2d382464987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 979 entries, 0 to 978\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Question  961 non-null    object\n",
            " 1   answer    939 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 15.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "yI7llg7uRie3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cedvT0fuRxds",
        "outputId": "83abdd30-7e1c-426a-9f6d-14de9bf962a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 937 entries, 0 to 978\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Question  937 non-null    object\n",
            " 1   answer    937 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 22.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After type error say:\"'float' object has no attribute 'lower'\", we should check the datatype of our data and fix them"
      ],
      "metadata": {
        "id": "HxcDyh7NQSh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtype_of_Q=set([type(i) for i in data['Question']])\n",
        "dtype_of_A=set([type(i) for i in data['answer']])\n",
        "print(f'Dtype of Questions: {dtype_of_Q}\\nDtype of Answers: {dtype_of_A}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2LFAcKHQRYS",
        "outputId": "320ca1fc-3b44-46fc-84a6-0a76b3d59db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dtype of Questions: {<class 'str'>}\n",
            "Dtype of Answers: {<class 'str'>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Problem solved after drop null lines, then all the data are string dtype"
      ],
      "metadata": {
        "id": "jvwJfL5FSob7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4- Prepare the data:\n"
      ],
      "metadata": {
        "id": "MbkGa2lwrZ-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean the sentences by removing special characters"
      ],
      "metadata": {
        "id": "6WfgTE72aQPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub(r'[^\\w]',' ',text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = \" \".join(filter(lambda x:x[0]!=\"@\", text.split()))\n",
        "    return text\n",
        "\n",
        "data['Question']=data['Question'].map(clean_text)\n",
        "data['answer']=data['answer'].map(clean_text)\n",
        "data"
      ],
      "metadata": {
        "id": "WVj4OxmprE7W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "17742b93-7b95-49ff-ff51-a47fc551c26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Question  \\\n",
              "0                                       hey   \n",
              "1                          do u have coffee   \n",
              "2    i will take one espresso and americano   \n",
              "3                          anything special   \n",
              "4                         suggest something   \n",
              "..                                      ...   \n",
              "974          what is price of french coffee   \n",
              "975       what is price of iced coffee late   \n",
              "976        what is price of latte macchiato   \n",
              "977   what is price of wainans choco coffee   \n",
              "978                         book me a table   \n",
              "\n",
              "                                                answer  \n",
              "0                             hello how may i help you  \n",
              "1    yes sir simple coffee cappuchino americano au ...  \n",
              "2    sir thanks for your order you have ordered esp...  \n",
              "3    we have coffe pastries puff pastries and milks...  \n",
              "4    we have coffe pastries puff pastries and milks...  \n",
              "..                                                 ...  \n",
              "974    its our one of best you can enjoy it at just rs  \n",
              "975    its our one of best you can enjoy it at just rs  \n",
              "976    its our one of best you can enjoy it at just rs  \n",
              "977    its our one of best you can enjoy it at just rs  \n",
              "978  to book a table you can click on last icon on ...  \n",
              "\n",
              "[937 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-229ec017-d605-42cf-865f-330a7d51349e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hey</td>\n",
              "      <td>hello how may i help you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>do u have coffee</td>\n",
              "      <td>yes sir simple coffee cappuchino americano au ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i will take one espresso and americano</td>\n",
              "      <td>sir thanks for your order you have ordered esp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anything special</td>\n",
              "      <td>we have coffe pastries puff pastries and milks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suggest something</td>\n",
              "      <td>we have coffe pastries puff pastries and milks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>what is price of french coffee</td>\n",
              "      <td>its our one of best you can enjoy it at just rs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>what is price of iced coffee late</td>\n",
              "      <td>its our one of best you can enjoy it at just rs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>what is price of latte macchiato</td>\n",
              "      <td>its our one of best you can enjoy it at just rs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>what is price of wainans choco coffee</td>\n",
              "      <td>its our one of best you can enjoy it at just rs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>book me a table</td>\n",
              "      <td>to book a table you can click on last icon on ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>937 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-229ec017-d605-42cf-865f-330a7d51349e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-229ec017-d605-42cf-865f-330a7d51349e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-229ec017-d605-42cf-865f-330a7d51349e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add a start and end token to each sentence"
      ],
      "metadata": {
        "id": "hoQcvUo2ahWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "def SE_adder(text):\n",
        "  return f'<START> {text} <END>'\n",
        "\n",
        "data['Question']=data['Question'].apply(SE_adder)\n",
        "data['answer']=data['answer'].apply(SE_adder)"
      ],
      "metadata": {
        "id": "nwpRSMy_ahWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize the sentences"
      ],
      "metadata": {
        "id": "pmVlBOehaiMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "def tok(lang):\n",
        "  tokenizer=tf.keras.preprocessing.text.Tokenizer(oov_token='<oov>',filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',lower=False) #filters should not contain < and > symbols\n",
        "  tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  output = tokenizer.texts_to_sequences(lang)\n",
        "  output = tf.keras.preprocessing.sequence.pad_sequences(output, padding='post',truncating='post')\n",
        "  return output,tokenizer\n",
        "\n",
        "Ques_seq,Q_tok=tok(data['Question'])\n",
        "Ans_seq,A_tok=tok(data['answer'])"
      ],
      "metadata": {
        "id": "Y9acRrtbaiMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=model_selection.train_test_split(Ques_seq,Ans_seq,test_size=0.1,random_state=42)"
      ],
      "metadata": {
        "id": "KArG-FSzgHUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[0]//32 + x_test.shape[0]//32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaxSPVHQv_z_",
        "outputId": "539ddbc8-0082-4285-eabb-e9b02932301f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5- Create the Data Pipeline for the Model"
      ],
      "metadata": {
        "id": "K5x6ahnDZZfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "def pipline(x,y):\n",
        "  d=tf.data.Dataset.from_tensor_slices((x,y))\n",
        "  d=d.shuffle(1028)\n",
        "  d=d.batch(32)\n",
        "  d=d.prefetch(tf.data.AUTOTUNE)\n",
        "  return d\n",
        "\n",
        "train_dataset=pipline(x_train,y_train)\n",
        "test_dataset=pipline(x_test,y_test)"
      ],
      "metadata": {
        "id": "OIrFkw5-Zfoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sentence(sequ,toke):\n",
        "  textout=[]\n",
        "  for t in sequ:\n",
        "    if t!=0:\n",
        "      textout.append(toke.index_word[t])\n",
        "    else: pass\n",
        "  textout=' '.join(textout)\n",
        "  textout=textout.replace('<START> ','')\n",
        "  textout=textout.replace(' <END>','')\n",
        "  return textout"
      ],
      "metadata": {
        "id": "juO4YS1igr7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_dataset.take(1):\n",
        "  print(f'Q: {decode_sentence(x[0].numpy(),Q_tok)}\\nA: {decode_sentence(y[0].numpy(),A_tok)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSGzl3oRgybV",
        "outputId": "422340fa-d4aa-4098-d2b8-0cb8f5b00963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: do u have good pastery\n",
            "A: yes sir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6- Create the Seq2Seq Model Architecture"
      ],
      "metadata": {
        "id": "nOEo3I9grsab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Encoder Model"
      ],
      "metadata": {
        "id": "EWC9UWmbZ5a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_vs=len(Q_tok.index_word)+1\n",
        "out_vs=len(A_tok.index_word)+1\n",
        "em_dim=200\n",
        "B_size=32"
      ],
      "metadata": {
        "id": "tputLdSGibnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self,embedding_dim,batch_size,vocab_size):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.batch_size=batch_size\n",
        "    self.emb=tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim)\n",
        "    self.gru=tf.keras.layers.GRU(256,return_sequences=True,return_state=True)\n",
        "    \n",
        "  def call(self,x,hidden_state):\n",
        "    x=self.emb(x)\n",
        "    out,state=self.gru(x,initial_state=hidden_state)    \n",
        "    return out,state\n",
        "\n",
        "  def encoder_initializer(self):\n",
        "    return tf.zeros((self.batch_size, 256)) "
      ],
      "metadata": {
        "id": "Fy6HA5ZIrFLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder Model"
      ],
      "metadata": {
        "id": "QdZTOtgxZwb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self,embedding_dim,batch_size,vocab_size,units):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.batch_size=batch_size\n",
        "    self.units=units\n",
        "    self.emb=tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim)\n",
        "    self.gru=tf.keras.layers.GRU(256,return_sequences=True,return_state=True)\n",
        "    \n",
        "    self.dense=tf.keras.layers.Dense(units=self.units)\n",
        "  def call(self,x,hidden_state):\n",
        "    x=self.emb(x)\n",
        "    out,state=self.gru(x,initial_state=hidden_state)\n",
        "    out = tf.reshape(out, (-1, out.shape[2]))\n",
        "    out = tf.nn.softmax(self.dense(out))\n",
        "    return out,state"
      ],
      "metadata": {
        "id": "ul17SieaaHuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_enc=Encoder(embedding_dim=em_dim,batch_size=B_size,vocab_size=in_vs)\n",
        "my_dec=Decoder(embedding_dim=em_dim,batch_size=B_size,vocab_size=out_vs,units=out_vs)"
      ],
      "metadata": {
        "id": "oC3C_SdtsQvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7- Create the Optimizer and the Loss Function"
      ],
      "metadata": {
        "id": "r1MUIcM2a3Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "OPT=tf.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  Loss = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=Loss.dtype)\n",
        "  loss = Loss * mask\n",
        "  return tf.reduce_mean(Loss)"
      ],
      "metadata": {
        "id": "0uosbAXObbMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8- Create the Training Step"
      ],
      "metadata": {
        "id": "iGYQ9J45a7nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.metrics.Mean(name='train loss')\n",
        "test_loss = tf.metrics.Mean(name='test loss')"
      ],
      "metadata": {
        "id": "a-rFip9MmD-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "\n",
        "@tf.function\n",
        "def train_step(input, target, encoder_hidden_state):\n",
        "\n",
        "  loss = 0\n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_hidden_state = my_enc(input, encoder_hidden_state)\n",
        "    decoder_hidden_state = encoder_hidden_state\n",
        "    decoder_input = tf.expand_dims([A_tok.word_index['<START>']] * input.shape[0], 1)\n",
        "    for t in range(1, target.shape[1]):\n",
        "      prediction, decoder_hidden_state = my_dec(decoder_input, decoder_hidden_state)\n",
        "      loss += loss_function(target[:, t], prediction)\n",
        "      decoder_input = tf.expand_dims(target[:, t], 1)\n",
        "  batch_loss = loss / int(target.shape[1]) \n",
        "  variables = my_enc.trainable_variables + my_dec.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  OPT.apply_gradients(zip(gradients, variables))\n",
        "  train_loss(batch_loss)\n",
        "  return batch_loss  "
      ],
      "metadata": {
        "id": "c-MMEEGCbVqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9- Create the Testing Loop"
      ],
      "metadata": {
        "id": "1TS48ppybDGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below\n",
        "@tf.function\n",
        "def test_step(input, target, encoder_hidden_state):\n",
        "\n",
        "  loss = 0\n",
        "  encoder_output, encoder_hidden_state = my_enc(input, encoder_hidden_state)\n",
        "  decoder_hidden_state = encoder_hidden_state\n",
        "  decoder_input = tf.expand_dims([A_tok.word_index['<START>']] * input.shape[0], 1) \n",
        "  for t in range(1, target.shape[1]):\n",
        "    prediction, decoder_hidden_state = my_dec(decoder_input, decoder_hidden_state)\n",
        "    loss += loss_function(target[:, t], prediction)\n",
        "    # teacher forcing\n",
        "    decoder_input = tf.expand_dims(target[:, t], 1)\n",
        "  batch_loss = loss / int(target.shape[1]) \n",
        "  test_loss(batch_loss)"
      ],
      "metadata": {
        "id": "bUfkQvyJbWA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate number of target of keras progbar, and each part of train half and test half"
      ],
      "metadata": {
        "id": "X4HFJiGvx7O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_take = x_train.shape[0]//32\n",
        "Test_take = x_test.shape[0]//32\n",
        "All_take = Train_take + Test_take"
      ],
      "metadata": {
        "id": "r_DnpypLx59q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Epoch = 50\n",
        "\n",
        "for epoch in range(Epoch):\n",
        "  train_loss.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  encoder_hidden_state = my_enc.encoder_initializer()\n",
        "  progress_bar = tf.keras.utils.Progbar(target= All_take)\n",
        "  batch_count = 0\n",
        "  for (batch, (input, target)) in enumerate(train_dataset.take(Train_take)):\n",
        "    batch_count += 1\n",
        "    train_step(input, target, encoder_hidden_state)\n",
        "    progress_bar.update(batch_count)\n",
        "\n",
        "  for (batch, (input, target)) in enumerate(test_dataset.take(Test_take)):\n",
        "    batch_count += 1\n",
        "    test_step(input, target, encoder_hidden_state)\n",
        "    progress_bar.update(batch_count)\n",
        "\n",
        "  print(f'Epoch: {epoch + 1} -  loss: {train_loss.result()} -------- val_loss: {test_loss.result()}')"
      ],
      "metadata": {
        "id": "W8qm1b_4tFhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed37c11-3e0f-45cc-d3bd-f369aeb07cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 100s 922ms/step\n",
            "Epoch: 1 -  loss: 2.5038657188415527 -------- val_loss: 1.5732766389846802\n",
            "28/28 [==============================] - 6s 202ms/step\n",
            "Epoch: 2 -  loss: 1.1397812366485596 -------- val_loss: 1.2616807222366333\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 3 -  loss: 1.0367209911346436 -------- val_loss: 1.1724615097045898\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 4 -  loss: 0.9398015141487122 -------- val_loss: 1.1464905738830566\n",
            "28/28 [==============================] - 5s 199ms/step\n",
            "Epoch: 5 -  loss: 0.7724625468254089 -------- val_loss: 0.9182495474815369\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 6 -  loss: 0.6759061217308044 -------- val_loss: 0.8503658771514893\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 7 -  loss: 0.5872515439987183 -------- val_loss: 0.8456438779830933\n",
            "28/28 [==============================] - 5s 198ms/step\n",
            "Epoch: 8 -  loss: 0.5019118189811707 -------- val_loss: 0.6690853834152222\n",
            "28/28 [==============================] - 6s 202ms/step\n",
            "Epoch: 9 -  loss: 0.4306097626686096 -------- val_loss: 0.5244592428207397\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 10 -  loss: 0.3878978192806244 -------- val_loss: 0.49540239572525024\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 11 -  loss: 0.34879186749458313 -------- val_loss: 0.4295429289340973\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 12 -  loss: 0.31025996804237366 -------- val_loss: 0.3969340920448303\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 13 -  loss: 0.27334508299827576 -------- val_loss: 0.3925817906856537\n",
            "28/28 [==============================] - 5s 198ms/step\n",
            "Epoch: 14 -  loss: 0.24196818470954895 -------- val_loss: 0.29673272371292114\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 15 -  loss: 0.2149801254272461 -------- val_loss: 0.28354790806770325\n",
            "28/28 [==============================] - 5s 198ms/step\n",
            "Epoch: 16 -  loss: 0.18604201078414917 -------- val_loss: 0.21629808843135834\n",
            "28/28 [==============================] - 5s 182ms/step\n",
            "Epoch: 17 -  loss: 0.16132031381130219 -------- val_loss: 0.18678268790245056\n",
            "28/28 [==============================] - 5s 195ms/step\n",
            "Epoch: 18 -  loss: 0.13972334563732147 -------- val_loss: 0.2072085440158844\n",
            "28/28 [==============================] - 5s 197ms/step\n",
            "Epoch: 19 -  loss: 0.1201917752623558 -------- val_loss: 0.13522830605506897\n",
            "28/28 [==============================] - 5s 197ms/step\n",
            "Epoch: 20 -  loss: 0.10311618447303772 -------- val_loss: 0.11358022689819336\n",
            "28/28 [==============================] - 5s 197ms/step\n",
            "Epoch: 21 -  loss: 0.09033433347940445 -------- val_loss: 0.11714273691177368\n",
            "28/28 [==============================] - 5s 198ms/step\n",
            "Epoch: 22 -  loss: 0.08090608566999435 -------- val_loss: 0.12754517793655396\n",
            "28/28 [==============================] - 5s 199ms/step\n",
            "Epoch: 23 -  loss: 0.07641218602657318 -------- val_loss: 0.1005316823720932\n",
            "28/28 [==============================] - 5s 197ms/step\n",
            "Epoch: 24 -  loss: 0.06389310956001282 -------- val_loss: 0.10078427195549011\n",
            "28/28 [==============================] - 5s 197ms/step\n",
            "Epoch: 25 -  loss: 0.056810397654771805 -------- val_loss: 0.08583346009254456\n",
            "28/28 [==============================] - 5s 199ms/step\n",
            "Epoch: 26 -  loss: 0.05197244510054588 -------- val_loss: 0.09815310686826706\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 27 -  loss: 0.0472012497484684 -------- val_loss: 0.07751370966434479\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 28 -  loss: 0.044013217091560364 -------- val_loss: 0.06503744423389435\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 29 -  loss: 0.041041355580091476 -------- val_loss: 0.061594363301992416\n",
            "28/28 [==============================] - 6s 202ms/step\n",
            "Epoch: 30 -  loss: 0.0379345528781414 -------- val_loss: 0.058590374886989594\n",
            "28/28 [==============================] - 6s 202ms/step\n",
            "Epoch: 31 -  loss: 0.03564636409282684 -------- val_loss: 0.05843808874487877\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 32 -  loss: 0.03351961448788643 -------- val_loss: 0.0506509467959404\n",
            "28/28 [==============================] - 10s 379ms/step\n",
            "Epoch: 33 -  loss: 0.03158547729253769 -------- val_loss: 0.05579887330532074\n",
            "28/28 [==============================] - 5s 199ms/step\n",
            "Epoch: 34 -  loss: 0.030209500342607498 -------- val_loss: 0.039215534925460815\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 35 -  loss: 0.029041511937975883 -------- val_loss: 0.05773445963859558\n",
            "28/28 [==============================] - 5s 199ms/step\n",
            "Epoch: 36 -  loss: 0.027827443554997444 -------- val_loss: 0.04225333407521248\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 37 -  loss: 0.026696158573031425 -------- val_loss: 0.0457003191113472\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 38 -  loss: 0.02569410391151905 -------- val_loss: 0.05244278162717819\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 39 -  loss: 0.024725161492824554 -------- val_loss: 0.04397285729646683\n",
            "28/28 [==============================] - 6s 199ms/step\n",
            "Epoch: 40 -  loss: 0.02421744540333748 -------- val_loss: 0.040535904467105865\n",
            "28/28 [==============================] - 5s 199ms/step\n",
            "Epoch: 41 -  loss: 0.023248739540576935 -------- val_loss: 0.040482960641384125\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 42 -  loss: 0.022526469081640244 -------- val_loss: 0.03753114491701126\n",
            "28/28 [==============================] - 6s 199ms/step\n",
            "Epoch: 43 -  loss: 0.022115694358944893 -------- val_loss: 0.027838781476020813\n",
            "28/28 [==============================] - 6s 199ms/step\n",
            "Epoch: 44 -  loss: 0.021251078695058823 -------- val_loss: 0.035761356353759766\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 45 -  loss: 0.020590271800756454 -------- val_loss: 0.03677365183830261\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 46 -  loss: 0.020376116037368774 -------- val_loss: 0.03345727548003197\n",
            "28/28 [==============================] - 5s 199ms/step\n",
            "Epoch: 47 -  loss: 0.019933942705392838 -------- val_loss: 0.031092725694179535\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 48 -  loss: 0.01951635628938675 -------- val_loss: 0.03386708348989487\n",
            "28/28 [==============================] - 6s 200ms/step\n",
            "Epoch: 49 -  loss: 0.019244998693466187 -------- val_loss: 0.03512514382600784\n",
            "28/28 [==============================] - 6s 201ms/step\n",
            "Epoch: 50 -  loss: 0.018777111545205116 -------- val_loss: 0.03419710323214531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicting function"
      ],
      "metadata": {
        "id": "dsR5HzoRWip7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chatbot function\n",
        "# the chatbot function takes in the question as input and answers the input sentence \n",
        "def chatbot(sentence):\n",
        "  \n",
        "  # clean the input question sentence \n",
        "  sentence = clean_text(sentence)\n",
        "  # add the start token to the sentence\n",
        "  sentence =SE_adder(sentence)\n",
        "  # tokenize the sentence\n",
        "  inputs = Q_tok.texts_to_sequences([sentence])\n",
        "  # pad the sentence\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,padding='post',truncating='post')\n",
        "  \n",
        "  # initalize the hidden state of the encoder to zeros\n",
        "  hidden = [tf.zeros((1, 256))]\n",
        "  # pass the sentence to the encoder with the hidden state as the initial hidden state\n",
        "  enc_out, enc_hidden = my_enc(inputs, hidden)\n",
        "  # set the initial decoder hidden state to the encoder hidden state\n",
        "  dec_hidden = enc_hidden\n",
        "  # create the start token\n",
        "  # start_token shape == (batch_size, 1)\n",
        "  # repeat the start token for the batch size times\n",
        "  dec_input = tf.expand_dims([A_tok.word_index['<START>']], 0)\n",
        "  # create the result string\n",
        "  result = ''\n",
        "  # loop over the length of the sentence (32)\n",
        "\n",
        "  for t in range(32):\n",
        "    # passing the encoder output and the decoder hidden state to the decoder make sure the decoder input is the previous predicted word\n",
        "    predictions, dec_hidden = my_dec(dec_input, dec_hidden)\n",
        "\n",
        "    # getting the predicted word index\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    # getting the predicted word using the predicted index\n",
        "    # add the predicted word to the result string \n",
        "    result += A_tok.index_word[predicted_id] + ' '\n",
        "    # if the predicted word is the <end> token then stop the loop\n",
        "    if A_tok.index_word[predicted_id] == '<END>':\n",
        "      # remove the <start> and <END> tokens from the result string\n",
        "      result = result.replace('<START> ', '')\n",
        "      result = result.replace(' <END> ','')\n",
        "      # remove the <START> and <END> tokens from the sentence string\n",
        "      sentence = sentence.replace('<START> ', '')\n",
        "      sentence = sentence.replace(' <END>', '')\n",
        "      return  sentence, result\n",
        "    # using the predicted word as the next decoder input\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  # remove the <START> and <END> tokens from the result string\n",
        "  result = result.replace('<START> ', '')\n",
        "  result = result.replace('<END>','')\n",
        "  # remove the <START> and <END> tokens from the sentence string\n",
        "  sentence = sentence.replace('<START> ', '')\n",
        "  sentence = sentence.replace('<END>', '')\n",
        "  \n",
        "  # return the result string and the original sentence\n",
        "  return sentence, result"
      ],
      "metadata": {
        "id": "0pQ276amhzRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot('price of french coffee')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHP-gQRdap3R",
        "outputId": "8a9ea3ec-5efe-4801-d35b-b5f7fae37c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('price of french coffee', 'its our one of best you can enjoy it at just rs')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sPH__PVLauxt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}